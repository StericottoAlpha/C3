"""
çµ±è¨ˆãƒ»åˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆstore_idå¼•æ•°ç‰ˆï¼‰
LangChain @tool ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ç”¨
"""
import logging
import json
from typing import Optional
from datetime import datetime, timedelta

from langchain_core.tools import tool

logger = logging.getLogger(__name__)

@tool
def get_claim_statistics(store_id: int, days: int = 30) -> str:
    """
    ã‚¯ãƒ¬ãƒ¼ãƒ çµ±è¨ˆã‚’å–å¾—ã—ã¾ã™ã€‚æŒ‡å®šæœŸé–“ã®ã‚¯ãƒ¬ãƒ¼ãƒ ä»¶æ•°ã€å†…å®¹ã®å‚¾å‘ã‚’åˆ†æã—ã¾ã™ã€‚
    """
    try:
        from reports.models import DailyReport
        from django.db.models import Count, Q
        from datetime import datetime, timedelta
        import json

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)

        # æœŸé–“å†…å…¨ãƒ‡ãƒ¼ã‚¿
        queryset = DailyReport.objects.filter(
            store_id=store_id,
            date__gte=start_date,
            date__lte=end_date
        )

        total_reports = queryset.count()

        # ğŸ¯ ã‚¯ãƒ¬ãƒ¼ãƒ ã¯ genre='claim'
        #    å†…å®¹ï¼ˆcontentï¼‰ãŒç©ºã§ãªã„ã‚‚ã®ã«é™å®š
        claim_reports = queryset.filter(
            genre='claim',
            content__isnull=False
        ).exclude(content='')

        claim_count = claim_reports.count()
        claim_rate = f"{(claim_count / total_reports * 100):.1f}%" if total_reports else "0%"

        # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæœ€è¿‘7æ—¥ï¼‰- DBã§é›†è¨ˆ
        recent_days = min(7, days)
        recent_start = end_date - timedelta(days=recent_days - 1)

        daily_trend_qs = claim_reports.filter(
            date__gte=recent_start
        ).values('date').annotate(
            count=Count('report_id')
        ).order_by('-date')

        # æ—¥ä»˜ã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã‚’ä½œæˆ
        trend_dict = {item['date']: item['count'] for item in daily_trend_qs}

        # å…¨æ—¥ä»˜ã‚’ç¶²ç¾…ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„æ—¥ã¯0ä»¶ï¼‰
        daily_trend = []
        for i in range(recent_days):
            target_date = end_date - timedelta(days=i)
            daily_trend.append({
                "date": str(target_date),
                "count": trend_dict.get(target_date, 0)
            })

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼ˆlocationï¼‰
        claim_by_genre = claim_reports.values('location').annotate(
            count=Count('report_id')
        ).order_by('-count')[:5]

        top_categories = [
            {"category": item['location'], "count": item['count']}
            for item in claim_by_genre
        ]

        result = {
            "status": "success",
            "store_id": store_id,
            "period_days": days,
            "summary": {
                "total_reports": total_reports,
                "claim_count": claim_count,
                "claim_rate": claim_rate
            },
            "daily_trend": daily_trend,
            "top_categories": top_categories
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in get_claim_statistics: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)



@tool
def get_sales_trend(store_id: int, days: int = 30) -> str:
    """
    Get sales trend data including total, average, customer count, daily trends, and weekly comparison.

    This tool retrieves structured sales performance data from the database and provides statistical analysis.

    When to use this tool:
    - When user asks about sales amounts, revenue, or sales performance (å£²ä¸Š)
    - When checking trends or patterns in sales data
    - When comparing with previous week/month sales
    - When analyzing customer count (å®¢æ•°) or average per customer (å®¢å˜ä¾¡)
    - Keywords: å£²ä¸Š, å£²ã‚Šä¸Šã’, åç›Š, å®¢æ•°, å®¢å˜ä¾¡

    Args:
        store_id: Store ID
        days: Number of days to aggregate (default: 30)

    Returns:
        JSON string containing sales trend data with summary, daily breakdown, and weekly comparison
    """
    try:
        from reports.models import StoreDailyPerformance
        from django.db.models import Sum, Avg, Max, Min, Count

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)

        # æœŸé–“å†…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        queryset = StoreDailyPerformance.objects.filter(
            store_id=store_id,
            date__gte=start_date,
            date__lte=end_date
        )

        # é›†è¨ˆãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        if not queryset.exists():
            return json.dumps({
                "status": "no_data",
                "message": f"æŒ‡å®šæœŸé–“ï¼ˆéå»{days}æ—¥é–“ï¼‰ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            }, ensure_ascii=False)

        # åŸºæœ¬çµ±è¨ˆ
        aggregates = queryset.aggregate(
            total_sales=Sum('sales_amount'),
            avg_sales=Avg('sales_amount'),
            max_sales=Max('sales_amount'),
            min_sales=Min('sales_amount'),
            total_customers=Sum('customer_count'),
            avg_customers=Avg('customer_count'),
            data_count=Count('performance_id')
        )

        # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæœ€æ–°7æ—¥åˆ†ï¼‰- DBã§ä¸€æ‹¬å–å¾—
        recent_days = min(7, days)
        recent_start = end_date - timedelta(days=recent_days - 1)

        daily_records = queryset.filter(
            date__gte=recent_start
        ).order_by('-date').values('date', 'sales_amount', 'customer_count')

        daily_data = [
            {
                "date": str(record['date']),
                "sales": record['sales_amount'],
                "customers": record['customer_count'],
                "avg_per_customer": round(record['sales_amount'] / record['customer_count'], 0)
                    if record['customer_count'] > 0 else 0
            }
            for record in daily_records
        ]

        # é€±æ¬¡æ¯”è¼ƒï¼ˆéå»2é€±é–“ï¼‰
        week_comparison = None
        if days >= 14:
            this_week_start = end_date - timedelta(days=6)
            last_week_start = end_date - timedelta(days=13)
            last_week_end = end_date - timedelta(days=7)

            this_week_sales = queryset.filter(
                date__gte=this_week_start, date__lte=end_date
            ).aggregate(total=Sum('sales_amount'))['total'] or 0

            last_week_sales = queryset.filter(
                date__gte=last_week_start, date__lte=last_week_end
            ).aggregate(total=Sum('sales_amount'))['total'] or 0

            if last_week_sales > 0:
                change_rate = (this_week_sales - last_week_sales) / last_week_sales * 100
                week_comparison = {
                    "this_week": this_week_sales,
                    "last_week": last_week_sales,
                    "change_amount": this_week_sales - last_week_sales,
                    "change_rate": f"{change_rate:.1f}%"
                }

        # å®¢å˜ä¾¡è¨ˆç®—
        total_sales = aggregates['total_sales'] or 0
        total_customers = aggregates['total_customers'] or 0
        avg_per_customer = round(total_sales / total_customers, 0) if total_customers > 0 else 0

        result = {
            "status": "success",
            "store_id": store_id,
            "period_days": days,
            "summary": {
                "data_count": aggregates['data_count'],
                "total_sales": total_sales,
                "avg_sales": round(aggregates['avg_sales'], 0) if aggregates['avg_sales'] else 0,
                "max_sales": aggregates['max_sales'] or 0,
                "min_sales": aggregates['min_sales'] or 0,
                "total_customers": total_customers,
                "avg_customers": round(aggregates['avg_customers'], 1) if aggregates['avg_customers'] else 0,
                "avg_per_customer": avg_per_customer
            },
            "daily_trend": daily_data,
            "week_comparison": week_comparison
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in get_sales_trend: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"å£²ä¸Šæ¨ç§»å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)


@tool
def get_cash_difference_analysis(store_id: int, days: int = 30) -> str:
    """
    Get cash difference (register discrepancy) analysis including total amount, frequency, and plus/minus breakdown.

    This tool analyzes cash register differences to identify cash management issues and patterns.

    When to use this tool:
    - When user asks about cash differences, register discrepancies (é•ç®—, ç¾é‡‘éä¸è¶³)
    - When checking cash management accuracy
    - When analyzing register closing issues (ãƒ¬ã‚¸ç· ã‚)
    - Keywords: é•ç®—, ç¾é‡‘éä¸è¶³, ãƒ¬ã‚¸å·®ç•°, é‡‘é¡å·®ç•°, ç¾é‡‘ç®¡ç†

    Args:
        store_id: Store ID
        days: Number of days to aggregate (default: 30)

    Returns:
        JSON string containing cash difference analysis with totals, frequency, and daily breakdown
    """
    try:
        from reports.models import StoreDailyPerformance
        from django.db.models import Sum, Avg, Max, Min, Count, Q

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)

        # æœŸé–“å†…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        queryset = StoreDailyPerformance.objects.filter(
            store_id=store_id,
            date__gte=start_date,
            date__lte=end_date
        )

        # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        if not queryset.exists():
            return json.dumps({
                "status": "no_data",
                "message": f"æŒ‡å®šæœŸé–“ï¼ˆéå»{days}æ—¥é–“ï¼‰ã®ç¾é‡‘éä¸è¶³ãƒ‡ãƒ¼ã‚¿ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            }, ensure_ascii=False)

        # åŸºæœ¬çµ±è¨ˆ
        aggregates = queryset.aggregate(
            total_difference=Sum('cash_difference'),
            avg_difference=Avg('cash_difference'),
            max_difference=Max('cash_difference'),
            min_difference=Min('cash_difference'),
            data_count=Count('performance_id')
        )

        # ãƒ—ãƒ©ã‚¹/ãƒã‚¤ãƒŠã‚¹ã®å†…è¨³
        plus_records = queryset.filter(cash_difference__gt=0)
        minus_records = queryset.filter(cash_difference__lt=0)
        zero_records = queryset.filter(cash_difference=0)

        plus_stats = plus_records.aggregate(
            count=Count('performance_id'),
            total=Sum('cash_difference'),
            avg=Avg('cash_difference')
        )

        minus_stats = minus_records.aggregate(
            count=Count('performance_id'),
            total=Sum('cash_difference'),
            avg=Avg('cash_difference')
        )

        # é•ç®—ç™ºç”Ÿæ—¥ã®åˆ†æ
        difference_occurred_count = queryset.exclude(cash_difference=0).count()
        difference_rate = f"{(difference_occurred_count / aggregates['data_count'] * 100):.1f}%" if aggregates['data_count'] > 0 else "0%"

        # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæœ€è¿‘7æ—¥é–“ã§é•ç®—ãŒã‚ã£ãŸæ—¥ï¼‰- DBã§ä¸€æ‹¬å–å¾—
        recent_days = min(7, days)
        recent_start = end_date - timedelta(days=recent_days - 1)

        daily_records = queryset.filter(
            date__gte=recent_start
        ).exclude(cash_difference=0).order_by('-date').values('date', 'cash_difference')

        daily_data = [
            {
                "date": str(record['date']),
                "difference": record['cash_difference'],
                "type": "ãƒ—ãƒ©ã‚¹" if record['cash_difference'] > 0 else "ãƒã‚¤ãƒŠã‚¹"
            }
            for record in daily_records
        ]

        result = {
            "status": "success",
            "store_id": store_id,
            "period_days": days,
            "summary": {
                "data_count": aggregates['data_count'],
                "total_difference": aggregates['total_difference'] or 0,
                "avg_difference": round(aggregates['avg_difference'], 0) if aggregates['avg_difference'] else 0,
                "max_difference": aggregates['max_difference'] or 0,
                "min_difference": aggregates['min_difference'] or 0,
                "difference_occurred_count": difference_occurred_count,
                "difference_rate": difference_rate,
                "zero_count": zero_records.count()
            },
            "plus_minus_breakdown": {
                "plus": {
                    "count": plus_stats['count'] or 0,
                    "total": plus_stats['total'] or 0,
                    "avg": round(plus_stats['avg'], 0) if plus_stats['avg'] else 0
                },
                "minus": {
                    "count": minus_stats['count'] or 0,
                    "total": minus_stats['total'] or 0,
                    "avg": round(minus_stats['avg'], 0) if minus_stats['avg'] else 0
                }
            },
            "recent_differences": daily_data
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in get_cash_difference_analysis: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"ç¾é‡‘éä¸è¶³åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)


@tool
def get_report_statistics(store_id: int, days: int = 30) -> str:
    """
    Get daily report statistics including genre breakdown (claims, praise, accidents, reports) and location analysis.

    This tool provides an overview of daily report submission patterns and categorization trends.

    When to use this tool:
    - When user wants an overview of daily reports (æ—¥å ±ã®å…¨ä½“åƒ)
    - When analyzing report submission frequency or patterns
    - When checking which genres (ã‚¸ãƒ£ãƒ³ãƒ«) or locations (å ´æ‰€) are most common
    - Keywords: æ—¥å ±çµ±è¨ˆ, å ±å‘Šä»¶æ•°, ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥, å ´æ‰€åˆ¥

    Args:
        store_id: Store ID
        days: Number of days to aggregate (default: 30)

    Returns:
        JSON string containing report statistics with genre/location breakdown
    """
    try:
        from reports.models import DailyReport
        from django.db.models import Count

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)

        # æœŸé–“å†…ã®æ—¥å ±ã‚’å–å¾—
        queryset = DailyReport.objects.filter(
            store_id=store_id,
            date__gte=start_date,
            date__lte=end_date
        )

        total_reports = queryset.count()

        if total_reports == 0:
            return json.dumps({
                "status": "no_data",
                "message": f"æŒ‡å®šæœŸé–“ï¼ˆéå»{days}æ—¥é–“ï¼‰ã®æ—¥å ±ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
            }, ensure_ascii=False)

        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥é›†è¨ˆ
        genre_breakdown = queryset.values('genre').annotate(
            count=Count('report_id')
        ).order_by('-count')

        genre_data = []
        for item in genre_breakdown:
            genre_display = dict(DailyReport.GENRE_CHOICES).get(item['genre'], item['genre'])
            percentage = (item['count'] / total_reports * 100) if total_reports > 0 else 0
            genre_data.append({
                "genre": item['genre'],
                "genre_display": genre_display,
                "count": item['count'],
                "percentage": f"{percentage:.1f}%"
            })

        # å ´æ‰€åˆ¥é›†è¨ˆ
        location_breakdown = queryset.values('location').annotate(
            count=Count('report_id')
        ).order_by('-count')

        location_data = []
        for item in location_breakdown:
            location_display = dict(DailyReport.LOCATION_CHOICES).get(item['location'], item['location'])
            percentage = (item['count'] / total_reports * 100) if total_reports > 0 else 0
            location_data.append({
                "location": item['location'],
                "location_display": location_display,
                "count": item['count'],
                "percentage": f"{percentage:.1f}%"
            })

        # æ—¥åˆ¥æŠ•ç¨¿é »åº¦ï¼ˆæœ€è¿‘7æ—¥é–“ï¼‰- DBã§é›†è¨ˆ
        recent_days = min(7, days)
        recent_start = end_date - timedelta(days=recent_days - 1)

        daily_submission_qs = queryset.filter(
            date__gte=recent_start
        ).values('date').annotate(
            count=Count('report_id')
        ).order_by('-date')

        # æ—¥ä»˜ã‚’ã‚­ãƒ¼ã«ã—ãŸè¾æ›¸ã‚’ä½œæˆ
        submission_dict = {item['date']: item['count'] for item in daily_submission_qs}

        # å…¨æ—¥ä»˜ã‚’ç¶²ç¾…ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„æ—¥ã¯0ä»¶ï¼‰
        daily_submission = []
        for i in range(recent_days):
            target_date = end_date - timedelta(days=i)
            daily_submission.append({
                "date": str(target_date),
                "count": submission_dict.get(target_date, 0)
            })

        result = {
            "status": "success",
            "store_id": store_id,
            "period_days": days,
            "summary": {
                "total_reports": total_reports,
                "avg_per_day": round(total_reports / days, 1)
            },
            "genre_breakdown": genre_data,
            "location_breakdown": location_data,
            "daily_submission": daily_submission
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in get_report_statistics: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"æ—¥å ±çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)


@tool
def get_monthly_goal_status(store_id: int) -> str:
    """
    Get monthly goal information including current month's goal, achievement rate, and past goal history.

    This tool helps track store goals and monitor progress toward targets.

    When to use this tool:
    - When user asks about monthly goals or targets (æœˆæ¬¡ç›®æ¨™, ç›®æ¨™é”æˆ)
    - When checking goal achievement status (é”æˆç‡)
    - When reviewing past goal performance
    - Keywords: ç›®æ¨™, æœˆæ¬¡ç›®æ¨™, é”æˆç‡, ç›®æ¨™é”æˆ

    Args:
        store_id: Store ID

    Returns:
        JSON string containing current goal status and historical data
    """
    try:
        from stores.models import MonthlyGoal

        current_date = datetime.now()
        current_year = current_date.year
        current_month = current_date.month

        # ä»Šæœˆã®ç›®æ¨™ã‚’å–å¾—
        current_goal = MonthlyGoal.objects.filter(
            store_id=store_id,
            year=current_year,
            month=current_month
        ).first()

        if not current_goal:
            return json.dumps({
                "status": "no_data",
                "message": f"{current_year}å¹´{current_month}æœˆã®ç›®æ¨™ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            }, ensure_ascii=False)

        # éå»6ãƒ¶æœˆã®ç›®æ¨™å±¥æ­´ã‚’å–å¾—
        past_goals = MonthlyGoal.objects.filter(
            store_id=store_id
        ).order_by('-year', '-month')[:6]

        past_goal_data = []
        for goal in past_goals:
            if goal.year == current_year and goal.month == current_month:
                continue  # ä»Šæœˆã®ç›®æ¨™ã¯é™¤å¤–
            past_goal_data.append({
                "year": goal.year,
                "month": goal.month,
                "goal_text": goal.goal_text,
                "achievement_rate": goal.achievement_rate,
                "achievement_text": goal.achievement_text
            })

        result = {
            "status": "success",
            "store_id": store_id,
            "current_goal": {
                "year": current_goal.year,
                "month": current_goal.month,
                "goal_text": current_goal.goal_text,
                "achievement_rate": current_goal.achievement_rate,
                "achievement_text": current_goal.achievement_text
            },
            "past_goals": past_goal_data[:5]  # æœ€å¤§5ä»¶ã®å±¥æ­´
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in get_monthly_goal_status: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"æœˆæ¬¡ç›®æ¨™å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)


@tool
def gather_topic_related_data(topic: str, store_id: int, days: int = 30) -> str:
    """
    Gather all related data about a specific topic from multiple sources (DATA COLLECTION ONLY).

    This tool performs comprehensive data retrieval across daily reports, BBS posts, and statistics.
    It does NOT analyze or interpret - it only collects and returns raw data for LLM analysis.

    When to use this tool:
    - When user asks for advice on a specific issue (å•é¡Œã«ã¤ã„ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹)
    - When analyzing a topic comprehensively (ç·åˆçš„ãªåˆ†æãŒå¿…è¦)
    - When you need context from multiple sources
    - Keywords: ã«ã¤ã„ã¦æ•™ãˆã¦, åˆ†æã—ã¦, ã‚¢ãƒ‰ãƒã‚¤ã‚¹, æ”¹å–„ç­–

    Args:
        topic: Topic keyword (e.g., "ã‚¯ãƒ¬ãƒ¼ãƒ ", "å£²ä¸Š", "æ¥å®¢", "äº‹æ•…")
        store_id: Store ID
        days: Search period in days (default: 30)

    Returns:
        JSON containing data from daily reports, BBS, and relevant statistics
    """
    try:
        from reports.models import DailyReport
        from bbs.models import BBSPost, BBSComment
        from django.db.models import Q, Count
        from datetime import datetime, timedelta

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)

        result = {
            "status": "success",
            "topic": topic,
            "store_id": store_id,
            "period_days": days,
            "data_sources": {}
        }

        # 1. æ—¥å ±ã‹ã‚‰ã®æƒ…å ±åé›†
        daily_reports = DailyReport.objects.filter(
            store_id=store_id,
            date__gte=start_date,
            date__lte=end_date
        ).filter(
            Q(title__icontains=topic) | Q(content__icontains=topic)
        ).order_by('-date')[:20]

        reports_data = []
        for report in daily_reports:
            reports_data.append({
                "date": str(report.date),
                "genre": dict(DailyReport.GENRE_CHOICES).get(report.genre, report.genre),
                "location": dict(DailyReport.LOCATION_CHOICES).get(report.location, report.location),
                "title": report.title,
                "content": report.content[:300],
                "author": report.user.user_id if report.user else "ä¸æ˜"
            })

        result["data_sources"]["daily_reports"] = {
            "count": len(reports_data),
            "items": reports_data
        }

        # 2. æ²ç¤ºæ¿ã‹ã‚‰ã®æƒ…å ±åé›† - prefetch_relatedã§N+1ã‚¯ã‚¨ãƒªè§£æ¶ˆ
        from django.db.models import Prefetch

        bbs_posts = BBSPost.objects.filter(
            store_id=store_id,
            created_at__date__gte=start_date,
            created_at__date__lte=end_date
        ).filter(
            Q(title__icontains=topic) | Q(content__icontains=topic)
        ).prefetch_related(
            Prefetch(
                'comments',
                queryset=BBSComment.objects.select_related('user').order_by('created_at')[:5],
                to_attr='recent_comments'
            ),
            'user'  # æŠ•ç¨¿è€…ã‚‚ä¸€ç·’ã«å–å¾—
        ).order_by('-created_at')[:15]

        bbs_data = []
        for post in bbs_posts:
            # prefetchã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨
            comment_list = [
                {
                    "author": comment.user.user_id if comment.user else "ä¸æ˜",
                    "content": comment.content[:200],
                    "created_at": comment.created_at.strftime("%Y-%m-%d %H:%M")
                }
                for comment in post.recent_comments
            ]

            bbs_data.append({
                "title": post.title,
                "content": post.content[:300],
                "author": post.user.user_id if post.user else "ä¸æ˜",
                "created_at": post.created_at.strftime("%Y-%m-%d"),
                "comment_count": post.comment_count,
                "comments": comment_list
            })

        result["data_sources"]["bbs_posts"] = {
            "count": len(bbs_data),
            "items": bbs_data
        }

        # 3. ãƒˆãƒ”ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹çµ±è¨ˆï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰
        topic_lower = topic.lower()
        statistics = {}

        if any(keyword in topic_lower for keyword in ["ã‚¯ãƒ¬ãƒ¼ãƒ ", "è‹¦æƒ…", "claim"]):
            # ã‚¯ãƒ¬ãƒ¼ãƒ çµ±è¨ˆã‚’è¿½åŠ 
            claim_reports = DailyReport.objects.filter(
                store_id=store_id,
                genre='claim',
                date__gte=start_date,
                date__lte=end_date
            )
            statistics["claim_count"] = claim_reports.count()
            statistics["claim_by_location"] = list(claim_reports.values('location').annotate(count=Count('report_id')).order_by('-count')[:3])

        if any(keyword in topic_lower for keyword in ["å£²ä¸Š", "å£²ã‚Šä¸Šã’", "sales", "revenue"]):
            # å£²ä¸Šçµ±è¨ˆã‚’è¿½åŠ 
            try:
                from reports.models import StoreDailyPerformance
                from django.db.models import Sum, Avg

                sales_data = StoreDailyPerformance.objects.filter(
                    store_id=store_id,
                    date__gte=start_date,
                    date__lte=end_date
                ).aggregate(
                    total=Sum('sales_amount'),
                    avg=Avg('sales_amount'),
                    count=Count('performance_id')
                )
                statistics["sales"] = {
                    "total": sales_data['total'] or 0,
                    "average": round(sales_data['avg'], 0) if sales_data['avg'] else 0,
                    "data_points": sales_data['count']
                }
            except Exception:
                pass

        if any(keyword in topic_lower for keyword in ["äº‹æ•…", "accident", "ãƒˆãƒ©ãƒ–ãƒ«"]):
            # äº‹æ•…çµ±è¨ˆã‚’è¿½åŠ 
            accident_reports = DailyReport.objects.filter(
                store_id=store_id,
                genre='accident',
                date__gte=start_date,
                date__lte=end_date
            )
            statistics["accident_count"] = accident_reports.count()

        result["data_sources"]["related_statistics"] = statistics

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in gather_topic_related_data: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"æƒ…å ±åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)


@tool
def compare_periods(store_id: int, metric: str, period1_days: int = 7, period2_days: int = 14) -> str:
    """
    Compare metrics between two time periods (STATISTICAL CALCULATION ONLY).

    This tool retrieves data for two periods and calculates comparison metrics.
    It does NOT interpret results - interpretation is the LLM's responsibility.

    When to use this tool:
    - When user asks about changes or trends (å¤‰åŒ–ã€æ¨ç§»ã€æ¯”è¼ƒ)
    - When comparing current vs previous performance
    - When analyzing if situation improved or worsened
    - Keywords: å…ˆé€±ã¨æ¯”ã¹ã¦, å‰å›ã¨æ¯”è¼ƒ, å¢—ãˆãŸ, æ¸›ã£ãŸ, å¤‰åŒ–

    Args:
        store_id: Store ID
        metric: Metric to compare (sales/claims/accidents/reports/cash_difference)
        period1_days: Recent period days (default: 7 for last week)
        period2_days: Comparison period days (default: 14, means 8-14 days ago)

    Returns:
        JSON with side-by-side comparison and calculated change rates
    """
    try:
        from reports.models import DailyReport, StoreDailyPerformance
        from django.db.models import Sum, Avg, Count

        end_date = datetime.now().date()

        # Period 1: ç›´è¿‘ï¼ˆä¾‹: éå»7æ—¥é–“ï¼‰
        period1_start = end_date - timedelta(days=period1_days)
        period1_end = end_date

        # Period 2: æ¯”è¼ƒå¯¾è±¡ï¼ˆä¾‹: 8-14æ—¥å‰ï¼‰
        period2_start = end_date - timedelta(days=period2_days)
        period2_end = end_date - timedelta(days=period1_days + 1)

        result = {
            "status": "success",
            "store_id": store_id,
            "metric": metric,
            "period1": {
                "label": f"ç›´è¿‘{period1_days}æ—¥é–“",
                "start": str(period1_start),
                "end": str(period1_end)
            },
            "period2": {
                "label": f"{period1_days + 1}ã€œ{period2_days}æ—¥å‰",
                "start": str(period2_start),
                "end": str(period2_end)
            }
        }

        if metric == "sales":
            # å£²ä¸Šæ¯”è¼ƒ
            p1_data = StoreDailyPerformance.objects.filter(
                store_id=store_id,
                date__gte=period1_start,
                date__lte=period1_end
            ).aggregate(
                total=Sum('sales_amount'),
                avg=Avg('sales_amount'),
                count=Count('performance_id')
            )

            p2_data = StoreDailyPerformance.objects.filter(
                store_id=store_id,
                date__gte=period2_start,
                date__lte=period2_end
            ).aggregate(
                total=Sum('sales_amount'),
                avg=Avg('sales_amount'),
                count=Count('performance_id')
            )

            p1_total = p1_data['total'] or 0
            p2_total = p2_data['total'] or 0
            change = p1_total - p2_total
            change_rate = (change / p2_total * 100) if p2_total > 0 else 0

            result["comparison"] = {
                "period1": {
                    "total": p1_total,
                    "average": round(p1_data['avg'], 0) if p1_data['avg'] else 0,
                    "data_points": p1_data['count']
                },
                "period2": {
                    "total": p2_total,
                    "average": round(p2_data['avg'], 0) if p2_data['avg'] else 0,
                    "data_points": p2_data['count']
                },
                "change": {
                    "absolute": change,
                    "rate": f"{change_rate:.1f}%",
                    "direction": "å¢—åŠ " if change > 0 else "æ¸›å°‘" if change < 0 else "å¤‰åŒ–ãªã—"
                }
            }

        elif metric == "claims":
            # ã‚¯ãƒ¬ãƒ¼ãƒ æ¯”è¼ƒ
            p1_count = DailyReport.objects.filter(
                store_id=store_id,
                genre='claim',
                date__gte=period1_start,
                date__lte=period1_end
            ).count()

            p2_count = DailyReport.objects.filter(
                store_id=store_id,
                genre='claim',
                date__gte=period2_start,
                date__lte=period2_end
            ).count()

            change = p1_count - p2_count
            change_rate = (change / p2_count * 100) if p2_count > 0 else 0

            result["comparison"] = {
                "period1": {"count": p1_count},
                "period2": {"count": p2_count},
                "change": {
                    "absolute": change,
                    "rate": f"{change_rate:.1f}%",
                    "direction": "å¢—åŠ " if change > 0 else "æ¸›å°‘" if change < 0 else "å¤‰åŒ–ãªã—"
                }
            }

        elif metric == "accidents":
            # äº‹æ•…æ¯”è¼ƒ
            p1_count = DailyReport.objects.filter(
                store_id=store_id,
                genre='accident',
                date__gte=period1_start,
                date__lte=period1_end
            ).count()

            p2_count = DailyReport.objects.filter(
                store_id=store_id,
                genre='accident',
                date__gte=period2_start,
                date__lte=period2_end
            ).count()

            change = p1_count - p2_count
            change_rate = (change / p2_count * 100) if p2_count > 0 else 0

            result["comparison"] = {
                "period1": {"count": p1_count},
                "period2": {"count": p2_count},
                "change": {
                    "absolute": change,
                    "rate": f"{change_rate:.1f}%",
                    "direction": "å¢—åŠ " if change > 0 else "æ¸›å°‘" if change < 0 else "å¤‰åŒ–ãªã—"
                }
            }

        elif metric == "reports":
            # æ—¥å ±å…¨ä½“ã®æ¯”è¼ƒ
            p1_count = DailyReport.objects.filter(
                store_id=store_id,
                date__gte=period1_start,
                date__lte=period1_end
            ).count()

            p2_count = DailyReport.objects.filter(
                store_id=store_id,
                date__gte=period2_start,
                date__lte=period2_end
            ).count()

            change = p1_count - p2_count
            change_rate = (change / p2_count * 100) if p2_count > 0 else 0

            result["comparison"] = {
                "period1": {"count": p1_count},
                "period2": {"count": p2_count},
                "change": {
                    "absolute": change,
                    "rate": f"{change_rate:.1f}%",
                    "direction": "å¢—åŠ " if change > 0 else "æ¸›å°‘" if change < 0 else "å¤‰åŒ–ãªã—"
                }
            }

        elif metric == "cash_difference":
            # ç¾é‡‘éä¸è¶³æ¯”è¼ƒ
            p1_data = StoreDailyPerformance.objects.filter(
                store_id=store_id,
                date__gte=period1_start,
                date__lte=period1_end
            ).aggregate(
                total=Sum('cash_difference'),
                avg=Avg('cash_difference'),
                count=Count('performance_id')
            )

            p2_data = StoreDailyPerformance.objects.filter(
                store_id=store_id,
                date__gte=period2_start,
                date__lte=period2_end
            ).aggregate(
                total=Sum('cash_difference'),
                avg=Avg('cash_difference'),
                count=Count('performance_id')
            )

            p1_total = p1_data['total'] or 0
            p2_total = p2_data['total'] or 0
            change = p1_total - p2_total

            result["comparison"] = {
                "period1": {
                    "total": p1_total,
                    "average": round(p1_data['avg'], 0) if p1_data['avg'] else 0
                },
                "period2": {
                    "total": p2_total,
                    "average": round(p2_data['avg'], 0) if p2_data['avg'] else 0
                },
                "change": {
                    "absolute": change,
                    "direction": "æ‚ªåŒ–" if abs(p1_total) > abs(p2_total) else "æ”¹å–„" if abs(p1_total) < abs(p2_total) else "å¤‰åŒ–ãªã—"
                }
            }

        else:
            return json.dumps({
                "status": "error",
                "message": f"æœªå¯¾å¿œã®metric: {metric}. æœ‰åŠ¹ãªå€¤: sales, claims, accidents, reports, cash_difference"
            }, ensure_ascii=False)

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in compare_periods: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"æœŸé–“æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)


# ============================================================
# å…¨åº—èˆ—çµ±è¨ˆãƒ„ãƒ¼ãƒ«ï¼ˆAll Storesï¼‰
# ============================================================

@tool
def get_claim_statistics_all_stores(days: int = 30) -> str:
    """
    å…¨åº—èˆ—ã®ã‚¯ãƒ¬ãƒ¼ãƒ çµ±è¨ˆã‚’å–å¾—ã—ã¾ã™ã€‚åº—èˆ—é–“ã®æ¯”è¼ƒã‚„å…¨ä½“å‚¾å‘ã‚’æŠŠæ¡ã§ãã¾ã™ã€‚

    When to use this tool:
    - When user wants to compare claims across all stores (å…¨åº—èˆ—ã®ã‚¯ãƒ¬ãƒ¼ãƒ æ¯”è¼ƒ)
    - When analyzing overall claim trends (å…¨ä½“çš„ãªã‚¯ãƒ¬ãƒ¼ãƒ å‚¾å‘)
    - When identifying stores with high/low claim rates

    Args:
        days: é›†è¨ˆæœŸé–“ï¼ˆæ—¥æ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥ï¼‰

    Returns:
        å…¨åº—èˆ—ã®ã‚¯ãƒ¬ãƒ¼ãƒ çµ±è¨ˆã®JSONæ–‡å­—åˆ—
    """
    try:
        from reports.models import DailyReport
        from stores.models import Store
        from django.db.models import Count, Q

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)

        # å…¨åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿
        all_reports = DailyReport.objects.filter(
            date__gte=start_date,
            date__lte=end_date
        )

        total_reports = all_reports.count()

        # ã‚¯ãƒ¬ãƒ¼ãƒ 
        claim_reports = all_reports.filter(
            genre='claim',
            content__isnull=False
        ).exclude(content='')

        claim_count = claim_reports.count()
        claim_rate = f"{(claim_count / total_reports * 100):.1f}%" if total_reports else "0%"

        # åº—èˆ—åˆ¥ã‚¯ãƒ¬ãƒ¼ãƒ æ•°
        claims_by_store = claim_reports.values(
            'store__store_name'
        ).annotate(
            count=Count('report_id')
        ).order_by('-count')[:10]

        store_breakdown = [
            {"store_name": item['store__store_name'], "count": item['count']}
            for item in claims_by_store
        ]

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼ˆlocationï¼‰
        claim_by_location = claim_reports.values('location').annotate(
            count=Count('report_id')
        ).order_by('-count')[:5]

        top_categories = [
            {"category": item['location'], "count": item['count']}
            for item in claim_by_location
        ]

        result = {
            "status": "success",
            "scope": "å…¨åº—èˆ—",
            "period_days": days,
            "summary": {
                "total_reports": total_reports,
                "claim_count": claim_count,
                "claim_rate": claim_rate
            },
            "store_breakdown": store_breakdown,
            "top_categories": top_categories
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in get_claim_statistics_all_stores: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"å…¨åº—èˆ—ã‚¯ãƒ¬ãƒ¼ãƒ çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)


@tool
def get_report_statistics_all_stores(days: int = 30) -> str:
    """
    å…¨åº—èˆ—ã®æ—¥å ±çµ±è¨ˆã‚’å–å¾—ã—ã¾ã™ã€‚åº—èˆ—é–“ã®æ´»å‹•é‡ã‚„å‚¾å‘ã‚’æ¯”è¼ƒã§ãã¾ã™ã€‚

    When to use this tool:
    - When comparing report submission across stores (åº—èˆ—é–“ã®æ—¥å ±æå‡ºçŠ¶æ³)
    - When analyzing overall reporting trends (å…¨ä½“çš„ãªå ±å‘Šå‚¾å‘)

    Args:
        days: é›†è¨ˆæœŸé–“ï¼ˆæ—¥æ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥ï¼‰

    Returns:
        å…¨åº—èˆ—ã®æ—¥å ±çµ±è¨ˆã®JSONæ–‡å­—åˆ—
    """
    try:
        from reports.models import DailyReport
        from django.db.models import Count

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)

        # å…¨åº—èˆ—ã®æ—¥å ±
        queryset = DailyReport.objects.filter(
            date__gte=start_date,
            date__lte=end_date
        )

        total_reports = queryset.count()

        if total_reports == 0:
            return json.dumps({
                "status": "no_data",
                "message": f"æŒ‡å®šæœŸé–“ï¼ˆéå»{days}æ—¥é–“ï¼‰ã®æ—¥å ±ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
            }, ensure_ascii=False)

        # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥é›†è¨ˆ
        genre_breakdown = queryset.values('genre').annotate(
            count=Count('report_id')
        ).order_by('-count')

        genre_data = []
        for item in genre_breakdown:
            genre_display = dict(DailyReport.GENRE_CHOICES).get(item['genre'], item['genre'])
            percentage = (item['count'] / total_reports * 100) if total_reports > 0 else 0
            genre_data.append({
                "genre": item['genre'],
                "genre_display": genre_display,
                "count": item['count'],
                "percentage": f"{percentage:.1f}%"
            })

        # åº—èˆ—åˆ¥é›†è¨ˆ
        store_breakdown = queryset.values('store__store_name').annotate(
            count=Count('report_id')
        ).order_by('-count')[:10]

        store_data = [
            {"store_name": item['store__store_name'], "count": item['count']}
            for item in store_breakdown
        ]

        result = {
            "status": "success",
            "scope": "å…¨åº—èˆ—",
            "period_days": days,
            "summary": {
                "total_reports": total_reports,
                "avg_per_day": round(total_reports / days, 1)
            },
            "genre_breakdown": genre_data,
            "store_breakdown": store_data
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in get_report_statistics_all_stores: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"å…¨åº—èˆ—æ—¥å ±çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)


@tool
def gather_topic_related_data_all_stores(topic: str, days: int = 30) -> str:
    """
    å…¨åº—èˆ—ã‹ã‚‰ç‰¹å®šãƒˆãƒ”ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¾ã™ã€‚

    When to use this tool:
    - When analyzing a topic across all stores (å…¨åº—èˆ—ã§ã®ãƒˆãƒ”ãƒƒã‚¯åˆ†æ)
    - When looking for best practices from any store
    - When comprehensive data is needed

    Args:
        topic: ãƒˆãƒ”ãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¾‹: "ã‚¯ãƒ¬ãƒ¼ãƒ ", "å£²ä¸Š", "æ¥å®¢"ï¼‰
        days: æ¤œç´¢æœŸé–“ï¼ˆæ—¥æ•°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30æ—¥ï¼‰

    Returns:
        å…¨åº—èˆ—ã®ãƒˆãƒ”ãƒƒã‚¯é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®JSONæ–‡å­—åˆ—
    """
    try:
        from reports.models import DailyReport
        from bbs.models import BBSPost, BBSComment
        from django.db.models import Q, Count

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)

        result = {
            "status": "success",
            "topic": topic,
            "scope": "å…¨åº—èˆ—",
            "period_days": days,
            "data_sources": {}
        }

        # 1. æ—¥å ±ã‹ã‚‰ã®æƒ…å ±åé›†ï¼ˆå…¨åº—èˆ—ï¼‰
        daily_reports = DailyReport.objects.filter(
            date__gte=start_date,
            date__lte=end_date
        ).filter(
            Q(title__icontains=topic) | Q(content__icontains=topic)
        ).order_by('-date')[:30]

        reports_data = []
        for report in daily_reports:
            reports_data.append({
                "date": str(report.date),
                "store_name": report.store.store_name if report.store else "ä¸æ˜",
                "genre": dict(DailyReport.GENRE_CHOICES).get(report.genre, report.genre),
                "location": dict(DailyReport.LOCATION_CHOICES).get(report.location, report.location),
                "title": report.title,
                "content": report.content[:300],
                "author": report.user.user_id if report.user else "ä¸æ˜"
            })

        result["data_sources"]["daily_reports"] = {
            "count": len(reports_data),
            "items": reports_data
        }

        # 2. æ²ç¤ºæ¿ã‹ã‚‰ã®æƒ…å ±åé›†ï¼ˆå…¨åº—èˆ—ï¼‰
        from django.db.models import Prefetch

        bbs_posts = BBSPost.objects.filter(
            created_at__date__gte=start_date,
            created_at__date__lte=end_date
        ).filter(
            Q(title__icontains=topic) | Q(content__icontains=topic)
        ).prefetch_related(
            Prefetch(
                'comments',
                queryset=BBSComment.objects.select_related('user').order_by('created_at')[:5],
                to_attr='recent_comments'
            ),
            'user',
            'store'
        ).order_by('-created_at')[:20]

        bbs_data = []
        for post in bbs_posts:
            comment_list = [
                {
                    "author": comment.user.user_id if comment.user else "ä¸æ˜",
                    "content": comment.content[:200],
                    "created_at": comment.created_at.strftime("%Y-%m-%d %H:%M")
                }
                for comment in post.recent_comments
            ]

            bbs_data.append({
                "store_name": post.store.store_name if post.store else "ä¸æ˜",
                "title": post.title,
                "content": post.content[:300],
                "author": post.user.user_id if post.user else "ä¸æ˜",
                "created_at": post.created_at.strftime("%Y-%m-%d"),
                "comment_count": post.comment_count,
                "comments": comment_list
            })

        result["data_sources"]["bbs_posts"] = {
            "count": len(bbs_data),
            "items": bbs_data
        }

        # 3. ãƒˆãƒ”ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹çµ±è¨ˆï¼ˆå…¨åº—èˆ—ï¼‰
        topic_lower = topic.lower()
        statistics = {}

        if any(keyword in topic_lower for keyword in ["ã‚¯ãƒ¬ãƒ¼ãƒ ", "è‹¦æƒ…", "claim"]):
            claim_reports = DailyReport.objects.filter(
                genre='claim',
                date__gte=start_date,
                date__lte=end_date
            )
            statistics["claim_count"] = claim_reports.count()
            statistics["claim_by_store"] = list(
                claim_reports.values('store__store_name')
                .annotate(count=Count('report_id'))
                .order_by('-count')[:5]
            )

        result["data_sources"]["related_statistics"] = statistics

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"Error in gather_topic_related_data_all_stores: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"å…¨åº—èˆ—æƒ…å ±åé›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
        }, ensure_ascii=False)