"""
AI Features Core Services
Ù¯ï¿½ï¿½"LLMï¿½ï¿½Ó¹nï¿½ï¿½
"""
import logging
from typing import List, Optional, Dict
import numpy as np

from sentence_transformers import SentenceTransformer

logger = logging.getLogger(__name__)


class EmbeddingService:
    """
    Æ­ï¿½ï¿½Ëï¿½ï¿½ï¿½Ó¹
    sentence-transformersï¿½(Wfï¿½ï¿½ï¿½ï¿½gÙ¯ï¿½ï¿½
    """

    MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2'
    DIMENSION = 384
    _model = None

    @classmethod
    def get_model(cls):
        """ï¿½ï¿½ï¿½nï¿½ï¿½ï¿½ï¿½ï¿½Ö—"""
        if cls._model is None:
            logger.info(f"Loading embedding model: {cls.MODEL_NAME}")
            cls._model = SentenceTransformer(cls.MODEL_NAME)
        return cls._model

    @classmethod
    def generate_embedding(cls, text: str) -> Optional[List[float]]:
        """
        Æ­ï¿½ï¿½Kï¿½Ù¯ï¿½ï¿½

        Args:
            text: Ù¯ï¿½ï¿½Yï¿½Æ­ï¿½ï¿½

        Returns:
            384!CnÙ¯ï¿½ï¿½1WBoNone	
        """
        if not text or not text.strip():
            logger.warning("Empty text provided for embedding")
            return None

        try:
            model = cls.get_model()
            embedding = model.encode(text, convert_to_numpy=True)

            # ï¿½ï¿½bk	ï¿½
            return embedding.tolist()

        except Exception as e:
            logger.error(f"Error generating embedding: {e}")
            return None

    @classmethod
    def generate_embeddings_batch(cls, texts: List[str]) -> List[Optional[List[float]]]:
        """
        pÆ­ï¿½ï¿½nï¿½ï¿½ï¿½Ù¯ï¿½ï¿½

        Args:
            texts: Ù¯ï¿½ï¿½Yï¿½Æ­ï¿½ï¿½nï¿½ï¿½

        Returns:
            Ù¯ï¿½ï¿½nï¿½ï¿½
        """
        if not texts:
            return []

        try:
            model = cls.get_model()

            # zï¿½Wï¿½dWfï¿½ï¿½ï¿½Ã¯ï¿½ï¿½ï¿½
            valid_texts = []
            valid_indices = []
            for i, text in enumerate(texts):
                if text and text.strip():
                    valid_texts.append(text)
                    valid_indices.append(i)

            if not valid_texts:
                return [None] * len(texts)

            # ï¿½ï¿½ï¿½ï¿½
            embeddings = model.encode(valid_texts, convert_to_numpy=True, show_progress_bar=True)

            # Pï¿½ï¿½Cnï¿½gï¿½ï¿½
            results = [None] * len(texts)
            for idx, embedding in zip(valid_indices, embeddings):
                results[idx] = embedding.tolist()

            return results

        except Exception as e:
            logger.error(f"Error in batch embedding generation: {e}")
            return [None] * len(texts)


class VectorizationService:
    """
    É­ï¿½ï¿½ï¿½ï¿½Ù¯ï¿½ï¿½ï¿½ï¿½Ó¹
    DocumentVectorï¿½ï¿½ï¿½xnÙ¯ï¿½ï¿½ï¿½X
    """

    @classmethod
    def vectorize_daily_report(cls, report_id: int) -> bool:
        """
        ï¿½1ï¿½Ù¯ï¿½ï¿½

        Args:
            report_id: ï¿½1ID

        Returns:
            ï¿½W_ï¿½True
        """
        from reports.models import DailyReport
        from ai_features.models import DocumentVector

        try:
            report = DailyReport.objects.get(report_id=report_id)

            # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
            content_parts = [
                f"ï¿½1: {report.report_date}",
                f"ï¿½: {report.store.store_name}",
                f"\: {report.user.get_full_name() or report.user.username}",
            ]

            # ï¿½ï¿½ï¿½ï¿½nï¿½ï¿½ï¿½ï¿½ï¿½
            if report.claim_content:
                content_parts.append(f"ï¿½ï¿½ï¿½ï¿½: {report.claim_content}")
            if report.praise_content:
                content_parts.append(f"ï¿½ï¿½: {report.praise_content}")
            if report.accident_content:
                content_parts.append(f"ï¿½E: {report.accident_content}")
            if report.other_content:
                content_parts.append(f"]nï¿½: {report.other_content}")

            content = "\n".join(content_parts)

            # Ù¯ï¿½ï¿½
            embedding = EmbeddingService.generate_embedding(content)
            if embedding is None:
                return False

            # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
            metadata = {
                'store_id': report.store.store_id,
                'store_name': report.store.store_name,
                'user_id': report.user.user_id,
                'user_name': report.user.get_full_name() or report.user.username,
                'date': str(report.report_date),
                'has_claim': bool(report.claim_content),
                'has_praise': bool(report.praise_content),
                'has_accident': bool(report.accident_content),
            }

            # ï¿½XnÙ¯ï¿½ï¿½ï¿½ï¿½~_o\
            DocumentVector.objects.update_or_create(
                source_type='daily_report',
                source_id=report_id,
                defaults={
                    'content': content,
                    'metadata': metadata,
                    'embedding': embedding,
                }
            )

            return True

        except Exception as e:
            logger.error(f"Error vectorizing daily report {report_id}: {e}")
            return False

    @classmethod
    def vectorize_bbs_post(cls, post_id: int) -> bool:
        """
        ï¿½:ï¿½?ï¿½Ù¯ï¿½ï¿½

        Args:
            post_id: ï¿½?ID

        Returns:
            ï¿½W_ï¿½True
        """
        from bbs.models import BBSPost
        from ai_features.models import DocumentVector

        try:
            post = BBSPost.objects.get(post_id=post_id)

            # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
            content = f"ï¿½ï¿½ï¿½ï¿½: {post.title}\nï¿½ï¿½: {post.content}"

            # Ù¯ï¿½ï¿½
            embedding = EmbeddingService.generate_embedding(content)
            if embedding is None:
                return False

            # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
            metadata = {
                'store_id': post.store.store_id,
                'store_name': post.store.store_name,
                'author_id': post.author.user_id,
                'author_name': post.author.get_full_name() or post.author.username,
                'title': post.title,
                'category': post.category,
                'date': str(post.created_at.date()),
            }

            # ï¿½XnÙ¯ï¿½ï¿½ï¿½ï¿½~_o\
            DocumentVector.objects.update_or_create(
                source_type='bbs_post',
                source_id=post_id,
                defaults={
                    'content': content,
                    'metadata': metadata,
                    'embedding': embedding,
                }
            )

            return True

        except Exception as e:
            logger.error(f"Error vectorizing BBS post {post_id}: {e}")
            return False

    @classmethod
    def vectorize_bbs_comment(cls, comment_id: int) -> bool:
        """
        ï¿½:ï¿½ï¿½ï¿½È’Ù¯ï¿½ï¿½

        Args:
            comment_id: ï¿½ï¿½ï¿½ï¿½ID

        Returns:
            ï¿½W_ï¿½True
        """
        from bbs.models import BBSComment
        from ai_features.models import DocumentVector

        try:
            comment = BBSComment.objects.get(comment_id=comment_id)

            # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½?ï¿½1ï¿½+ï¿½ï¿½	
            content = f"ï¿½?ï¿½ï¿½ï¿½ï¿½: {comment.post.title}\nï¿½ï¿½ï¿½ï¿½: {comment.content}"

            # Ù¯ï¿½ï¿½
            embedding = EmbeddingService.generate_embedding(content)
            if embedding is None:
                return False

            # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
            metadata = {
                'store_id': comment.post.store.store_id,
                'store_name': comment.post.store.store_name,
                'author_id': comment.author.user_id,
                'author_name': comment.author.get_full_name() or comment.author.username,
                'post_id': comment.post.post_id,
                'post_title': comment.post.title,
                'date': str(comment.created_at.date()),
            }

            # ï¿½XnÙ¯ï¿½ï¿½ï¿½ï¿½~_o\
            DocumentVector.objects.update_or_create(
                source_type='bbs_comment',
                source_id=comment_id,
                defaults={
                    'content': content,
                    'metadata': metadata,
                    'embedding': embedding,
                }
            )

            return True

        except Exception as e:
            logger.error(f"Error vectorizing BBS comment {comment_id}: {e}")
            return False


class VectorSearchService:
    """
    ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹
    PgVectorã‚’ä½¿ç”¨ã—ãŸã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢
    """

    @classmethod
    def search_documents(
        cls,
        query: str,
        user,
        source_types: Optional[List[str]] = None,
        filters: Optional[Dict] = None,
        top_k: int = 5
    ) -> List[Dict]:
        """
        å®Ÿç¸¾RAGæ¤œç´¢ï¼ˆDocumentVectorï¼‰

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            user: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            source_types: ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆï¼ˆ['daily_report', 'bbs_post']ç­‰ï¼‰
            filters: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆstore_id, dateç­‰ï¼‰
            top_k: å–å¾—ä»¶æ•°

        Returns:
            æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
        """
        from ai_features.models import DocumentVector
        from django.db import connection

        # ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        query_embedding = EmbeddingService.generate_embedding(query)
        if query_embedding is None:
            logger.error("Failed to generate query embedding")
            return []

        # WHEREå¥æ§‹ç¯‰
        where_clauses = []
        params = [query_embedding]

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åº—èˆ—ã§ãƒ•ã‚£ãƒ«ã‚¿
        if hasattr(user, 'store'):
            where_clauses.append("metadata->>'store_id' = %s")
            params.append(str(user.store.store_id))

        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿
        if source_types:
            placeholders = ','.join(['%s'] * len(source_types))
            where_clauses.append(f"source_type IN ({placeholders})")
            params.extend(source_types)

        # è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿
        if filters:
            for key, value in filters.items():
                if key == 'date':
                    where_clauses.append("metadata->>'date' = %s")
                    params.append(str(value))
                elif key == 'date_from':
                    where_clauses.append("metadata->>'date' >= %s")
                    params.append(str(value))
                elif key == 'date_to':
                    where_clauses.append("metadata->>'date' <= %s")
                    params.append(str(value))
                elif key == 'genre':
                    where_clauses.append("metadata->>'genre' = %s")
                    params.append(str(value))
                elif key == 'user_id':
                    where_clauses.append("metadata->>'user_id' = %s")
                    params.append(str(value))

        where_clause = " AND ".join(where_clauses) if where_clauses else "1=1"

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«query_embeddingã¨top_kã‚’è¿½åŠ 
        params.append(query_embedding)
        params.append(top_k)

        # SQLå®Ÿè¡Œ
        sql = f"""
            SELECT
                vector_id,
                source_type,
                source_id,
                content,
                metadata,
                1 - (embedding <=> %s::vector) AS similarity
            FROM document_vectors
            WHERE {where_clause}
            ORDER BY embedding <=> %s::vector
            LIMIT %s
        """

        try:
            with connection.cursor() as cursor:
                cursor.execute(sql, params)
                columns = [col[0] for col in cursor.description]
                results = [dict(zip(columns, row)) for row in cursor.fetchall()]

            return results

        except Exception as e:
            logger.error(f"Error in vector search: {e}")
            return []

    @classmethod
    def search_knowledge(
        cls,
        query: str,
        category: Optional[str] = None,
        document_type: Optional[str] = None,
        top_k: int = 3
    ) -> List[Dict]:
        """
        ãƒŠãƒ¬ãƒƒã‚¸RAGæ¤œç´¢ï¼ˆKnowledgeVectorï¼‰

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            category: ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ'hygiene', 'service'ç­‰ï¼‰
            document_type: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ'manual', 'guideline'ç­‰ï¼‰
            top_k: å–å¾—ä»¶æ•°

        Returns:
            æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆ
        """
        from ai_features.models import KnowledgeVector
        from django.db import connection

        # ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        query_embedding = EmbeddingService.generate_embedding(query)
        if query_embedding is None:
            logger.error("Failed to generate query embedding")
            return []

        # WHEREå¥æ§‹ç¯‰
        where_clauses = []
        params = [query_embedding]

        if category:
            where_clauses.append("metadata->>'category' = %s")
            params.append(category)

        if document_type:
            where_clauses.append("document_type = %s")
            params.append(document_type)

        where_clause = " AND ".join(where_clauses) if where_clauses else "1=1"

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«query_embeddingã¨top_kã‚’è¿½åŠ 
        params.append(query_embedding)
        params.append(top_k)

        # SQLå®Ÿè¡Œ
        sql = f"""
            SELECT
                vector_id,
                document_id,
                document_type,
                content,
                metadata,
                1 - (embedding <=> %s::vector) AS similarity
            FROM knowledge_vectors
            WHERE {where_clause}
            ORDER BY embedding <=> %s::vector
            LIMIT %s
        """

        try:
            with connection.cursor() as cursor:
                cursor.execute(sql, params)
                columns = [col[0] for col in cursor.description]
                results = [dict(zip(columns, row)) for row in cursor.fetchall()]

            return results

        except Exception as e:
            logger.error(f"Error in knowledge vector search: {e}")
            return []


class QueryClassifier:
    """
    ã‚¯ã‚¨ãƒªåˆ†é¡ã‚µãƒ¼ãƒ“ã‚¹
    ã‚¯ã‚¨ãƒªã®æ€§è³ªã«å¿œã˜ã¦å‹•çš„ã«Top-Kå€¤ã‚’æ±ºå®š
    """

    @classmethod
    def classify_and_get_top_k(cls, query: str) -> int:
        """
        ã‚¯ã‚¨ãƒªã®æ€§è³ªã«å¿œã˜ã¦Top-Kå€¤ã‚’æ±ºå®š

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª

        Returns:
            æ¨å¥¨Top-Kå€¤
        """
        # ç‰¹å®šã®äº‹ä¾‹æ¤œç´¢ï¼ˆæ˜ç¢ºï¼‰â†’ å°‘ãªã‚
        if any(keyword in query for keyword in ['åº—', 'æ—¥', 'æœˆ', 'ID']):
            # æ—¥ä»˜ã‚„åº—èˆ—ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ = æ˜ç¢ºãªã‚¯ã‚¨ãƒª
            return 3

        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆå‚¾å‘æŠŠæ¡ï¼‰â†’ ä¸­ç¨‹åº¦
        if any(keyword in query for keyword in ['å‚¾å‘', 'å¤šã„', 'å¢—åŠ ', 'æ¸›å°‘', 'æ¨ç§»']):
            return 12

        # åŒ…æ‹¬çš„èª¿æŸ»ï¼ˆå…¨ä½“åƒï¼‰â†’ å¤šã‚
        if any(keyword in query for keyword in ['å…¨ã¦', 'ä¸€è¦§', 'ã™ã¹ã¦', 'å…¨ä½“']):
            return 20

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return 5

    @classmethod
    def is_ambiguous(cls, query: str) -> bool:
        """
        ã‚¯ã‚¨ãƒªãŒæ›–æ˜§ã‹ã©ã†ã‹ã‚’åˆ¤å®š

        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª

        Returns:
            æ›–æ˜§ãªã‚‰True
        """
        # æ›–æ˜§ãªæ™‚é–“è¡¨ç¾
        ambiguous_time = ['æ˜¨æ—¥', 'å‰æ—¥', 'æœ€è¿‘', 'å…ˆé€±', 'å…ˆæœˆ', 'ä»Šé€±', 'ä»Šæœˆ']
        if any(word in query for word in ambiguous_time):
            return True

        # æŠ½è±¡çš„ãªè¡¨ç¾
        ambiguous_terms = ['å•é¡Œ', 'ãƒˆãƒ©ãƒ–ãƒ«', 'ä»¶', 'ã“ã¨', 'ã‚‚ã®', 'ã‚„ã¤']
        if any(word in query for word in ambiguous_terms):
            # å…·ä½“çš„ãªæ—¥ä»˜ã‚„åå‰ãŒãªã„å ´åˆã®ã¿æ›–æ˜§ã¨åˆ¤å®š
            if not any(char.isdigit() for char in query):
                return True

        return False
